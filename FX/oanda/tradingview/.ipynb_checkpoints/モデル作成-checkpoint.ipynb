{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#numpy配列を省略しないようにする\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#pandasを省略しないようにする\n",
    "pd.set_option('display.max_columns', 500) # 列\n",
    "pd.set_option('display.max_rows', 500)  # 行\n",
    "\n",
    "mm = preprocessing.MinMaxScaler()  # 正規化エンコード、デコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 正規化関数\n",
    "def mmscaler(data):\n",
    "    mm = preprocessing.MinMaxScaler()  # 正規化エンコード、デコード\n",
    "    dat = mm.fit_transform(data)\n",
    "    return dat\n",
    "\n",
    "# 目的変数の作成関数 1:df 2:目的変数のカラム名称 3:shiftさせるカラム名称 4:shiftする数\n",
    "def shift(df, t_name, t_column, shift):\n",
    "    df[t_name] = df[t_column].shift(shift) # 1行上にずらして5分後の値にしている\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータの作成\n",
    "def create_data(read_dir, save_dir):\n",
    "    df = pd.read_csv(read_dir, encoding='shift_jis')\n",
    "    #カラムを削除\n",
    "    df = df.dropna()  # NaNを削除\n",
    "    #df.drop(labels='日付(ローソク足)', axis=1, inplace=True) # ろうそく足データの日付\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time']  )#, format='%Y-%m-%d-%A %H:%M:%S')  # 日付カラムを日付型に変換\n",
    "    df['time(hour)'] = df['time'].dt.hour  # hourをデータに追加\n",
    "    df['time(minute)'] = df['time'].dt.minute  # minuteをデータに追加\n",
    "    df['time(weekday)'] = df['time'].dt.dayofweek  # minuteをデータに追加\n",
    "    # df['日付']カラムが [datetime64[ns]]型になっていて扱いづらいので最後に削除する\n",
    "    #df.drop(labels='日付', axis=1, inplace=True)\n",
    "    \n",
    "    date = df['time'] # 代入して変数を避難させる\n",
    "    \n",
    "    \n",
    "    shift(df, 'y_rate_1h', 'close', -1)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_2h', 'close', -2)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_3h', 'close', -3)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_4h', 'close', -4)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_5h', 'close', -5)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_6h', 'close', -6)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_7h', 'close', -7)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_8h', 'close', -8)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_9h', 'close', -9)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_10h', 'close', -10)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_11h', 'close', -11)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_12h', 'close', -12)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_13h', 'close', -13)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_14h', 'close', -14)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_15h', 'close', -15)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_16h', 'close', -16)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_17h', 'close', -17)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_18h', 'close', -18)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_19h', 'close', -19)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_20h', 'close', -20)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_21h', 'close', -21)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_22h', 'close', -22)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_23h', 'close', -23)  # 目的変数の作成関数\n",
    "    shift(df, 'y_rate_24h', 'close', -24)  # 目的変数の作成関数\n",
    "\n",
    "    \n",
    "    df = df.dropna()  # NaNを削除\n",
    "    #df = df.loc[:, '2':'time(weekday)'].astype('float32')  # データ型をfloatに変換して代入\n",
    "    #df.insert(0, 'time(week)', date)  # 日付を1列目に代入\n",
    "    #df.to_csv(save_dir , encoding='shift_jis', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数宣言\n",
    "read_dir = \"./tradingview/FX_GBPJPY, 60.csv\"\n",
    "save_dir =  \"./model/after.csv\"\n",
    "\n",
    "\n",
    "after = -1 # shift関数のスライド数 (1行上にずらして-分後の値にしている)\n",
    "name = '4h'\n",
    "t_column = 'close'  # 目的変数のカラム\n",
    "t_name = 'y_rate_5m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './shape/1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b6c0f6d09424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ***************************************トレーニングデータの作成***************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./model/中間ファイル.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'shift_jis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# ***************************************トレーニングデータの作成***************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-91e26adbbd78>\u001b[0m in \u001b[0;36mcreate_data\u001b[1;34m(read_dir, save_dir)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# トレーニングデータの作成\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'shift_jis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m#カラムを削除\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# NaNを削除\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hnmwt\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hnmwt\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hnmwt\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hnmwt\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hnmwt\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1991\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './shape/1.csv'"
     ]
    }
   ],
   "source": [
    "# ***************************************トレーニングデータの作成***************************************\n",
    "df = create_data(read_dir, save_dir)\n",
    "df.to_csv(\"./model/中間ファイル.csv\", encoding='shift_jis', index=False)\n",
    "# ***************************************トレーニングデータの作成***************************************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create():\n",
    "    #n_inputs = len(X_train.columns)  # 入力数\n",
    "    model = keras.models.Sequential()\n",
    "   # model.add(keras.layers.Dense(1200, activation='sigmoid'))\n",
    "   # model.add(keras.layers.Dense(300, activation='sigmoid'))\n",
    "   # model.add(keras.layers.Dense(6, activation='linear'))\n",
    "    model.add(keras.layers.LSTM(1, activation='linear',\n",
    "                  #recurrent_activation='sigmoid',\n",
    "                  kernel_initializer='glorot_normal',\n",
    "                   recurrent_initializer='orthogonal',\n",
    "                               batch_input_shape=(None, n_inputs, 1)))\n",
    "    #model.add(keras.layers.Dense(1200, activation='linear'))\n",
    "    #model.add(keras.layers.Dense(100, activation='linear'))\n",
    "    #model.add(keras.layers.Dense(50, activation='linear'))\n",
    "    #model.add(keras.layers.Dense(7, activation='linear'))\n",
    "    #model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.1)  # オプティマイザ\n",
    "    loss_fn = keras.losses.mse  # 損失関数\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=['mae'])  # コンパイル\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力したインプットデータを正規化、形状を整える関数\n",
    "def create_traindata(df, X_train, y_train):\n",
    "\n",
    "    print('入力数:', X_train.columns)\n",
    "    row_count = len(y_train)  # 行数を取得(形状の作成に使用)\n",
    "    column_count = len(X_train.columns)  # 列数を取得(形状の作成に使用)\n",
    "    \n",
    "    print('行数:', row_count)\n",
    "    print('列数:', column_count)\n",
    "    print('整形前の形状(特徴量):', X_train.shape)\n",
    "    X_train = mm.fit_transform(X_train)  # 正規化\n",
    "    X_train = np.array(X_train).reshape(row_count, column_count, -1)  # 特徴量の形状(3次元)\n",
    "    y_train = np.array(y_train).reshape(row_count,1)  # 特徴量の形状\n",
    "    y_train = mm.fit_transform(y_train)  # 正規化\n",
    "\n",
    "    print('形状(特徴量):', X_train.shape)\n",
    "    print('形状(目的変数):', y_train.shape)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習関数\n",
    "def learn_model(X_train, y_train, model_name, param_name, epochs):\n",
    "    model = model_create()  # モデル作成\n",
    "    earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "    \n",
    "    # 学習 LSTM_GBPJPY\n",
    "    print('モデルの学習を開始します')\n",
    "    history_model = model.fit(X_train, y_train, batch_size=1,epochs=epochs,validation_split=0.05,\n",
    "                                                  callbacks=[\n",
    "                                                  #tensorboard,\n",
    "                                                  earlystopping\n",
    "                                                  ])\n",
    "    \n",
    "    model.save(model_name)  # モデルを保存\n",
    "    model.save_weights(param_name)  # 重みを保存\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測関数\n",
    "def predict(model, X_train, y_train):\n",
    "    y_pred_one = model(X_train[-2:-1])  # 最終行の予測\n",
    "    y_pred = model(X_train)\n",
    "    y_pred_one = mm.inverse_transform(y_pred_one)  # 予測結果の正規化をデコード\n",
    "    y_pred = mm.inverse_transform(y_pred)  # 予測結果の正規化をデコード\n",
    "    y_train = mm.inverse_transform(y_train)  # 実際の結果の正規化をデコード\n",
    "    return y_pred_one, y_pred, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# プロット関数\n",
    "def plot_result(y_pred, y_train, title):\n",
    "    flg = plt.figure()\n",
    "    fig = plt.figure(figsize=(6, 4), dpi=72, linewidth=10)\n",
    "    ax = fig.add_subplot(111, xlabel='number', ylabel='price',title=title)  # グラフ作成\n",
    "    \n",
    "    ax.plot(y_train, label='actual')  # 実測\n",
    "    ax.plot(y_pred, label='predict')  # 予測\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数\n",
    "def learn(df, X_train, y_rate, title, epochs, model_dir, param_dir):\n",
    "    #**********1時間後予測**********学習のinput情報(特徴量、答え)\n",
    "    y_train = df.loc[:, y_rate]  # 全行 , 最終列\n",
    "    X_train, y_train = create_traindata(df, X_train, y_train)  # 入力したインプットデータをdropna、正規化、形状を整える\n",
    "    model = learn_model(X_train, y_train, model_dir, param_dir, epochs)  # モデルの学習\n",
    "    y_pred_one, y_pred, y_train = predict(model, X_train, y_train) # 予測\n",
    "    #y_train = df.loc[:, y_rate]  # y_trainを代入しなおす\n",
    "    plot_result(y_pred, y_train, title)  # プロット\n",
    "   # y_pred = model(X_train.iloc[-1])\n",
    "    return y_pred_one, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_trainデータ作成\n",
    "df = df.dropna()  # Nanを削除\n",
    "X_train = df.loc[:, 'open':'time(weekday)']  # 全行 , 列名称(始まり):列名称(終わり)\n",
    "n_inputs = len(X_train.columns)  # 入力数\n",
    "#X_train[-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('model.hdf5')  # モデルを読込み\n",
    "#model.load_weights('param.hdf5')  # 重みを読込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.hdf5')  # モデルを保存\n",
    "#model.save_weights('param.hdf5')  # 重みを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"廃止\n",
    "# n時間後の時刻とレートを計算してdfに反映関数\n",
    "def UNIX_RATE_conversion(df, time, name):\n",
    "    # UNIX時間に変更\n",
    "    df['日付UNIX'] = pd.to_datetime(df['日付']).dt.tz_localize('Asia/Tokyo')\n",
    "    df['日付UNIX'] = df['日付UNIX'].astype('int64') // 10**9\n",
    "    \n",
    "    df['日付UNIX' + name] = df['日付UNIX'].shift(time) # 1行上にずらして5分後の値にしている\n",
    "    df['日付UNIX_計算後' + name] = df['日付UNIX' + name] - df['日付UNIX'] # -分後の値か表した変数\n",
    "    df['RATE' + name] = df['bid_close'].shift(time)\n",
    "\n",
    "    return df  # n分後のUNIX時間、レートの計算結果を反映している\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '1h'\n",
    "y_pred_1h, y_pred = learn(df, X_train, 'y_rate_1h', 'graph_title', epochs, './model/GBPJPY_1h/model.hdf5','./model/GBPJPY_1h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '2h'\n",
    "y_pred_2h, y_pred = learn(df, X_train, 'y_rate_2h', 'graph_title', epochs, './model/GBPJPY_2h/model.hdf5','./model/GBPJPY_2h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '3h'\n",
    "y_pred_3h, y_pred = learn(df, X_train, 'y_rate_3h', 'graph_title', epochs, './model/GBPJPY_3h/model.hdf5','./model/GBPJPY_3h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '4h'\n",
    "y_pred_4h, y_pred = learn(df, X_train, 'y_rate_4h', 'graph_title', epochs, './model/GBPJPY_4h/model.hdf5','./model/GBPJPY_4h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '5h'\n",
    "y_pred_5h, y_pred = learn(df, X_train, 'y_rate_5h', 'graph_title', epochs, './model/GBPJPY_5h/model.hdf5','./model/GBPJPY_5h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '6h'\n",
    "y_pred_6h, y_pred = learn(df, X_train, 'y_rate_6h', 'graph_title', epochs, './model/GBPJPY_6h/model.hdf5','./model/GBPJPY_6h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '7h'\n",
    "y_pred_7h, y_pred = learn(df, X_train, 'y_rate_7h', 'graph_title', epochs, './model/GBPJPY_7h/model.hdf5','./model/GBPJPY_1h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '8h'\n",
    "y_pred_8h, y_pred = learn(df, X_train, 'y_rate_8h', 'graph_title', epochs, './model/GBPJPY_8h/model.hdf5','./model/GBPJPY_8h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '9h'\n",
    "y_pred_9h, y_pred = learn(df, X_train, 'y_rate_9h', 'graph_title', epochs, './model/GBPJPY_9h/model.hdf5','./model/GBPJPY_9h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '10h'\n",
    "y_pred_10h, y_pred = learn(df, X_train, 'y_rate_10h', 'graph_title', epochs, './model/GBPJPY_10h/model.hdf5','./model/GBPJPY_10h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '11h'\n",
    "y_pred_11h, y_pred = learn(df, X_train, 'y_rate_11h', 'graph_title', epochs, './model/GBPJPY_11h/model.hdf5','./model/GBPJPY_11h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '12h'\n",
    "y_pred_12h, y_pred = learn(df, X_train, 'y_rate_12h', 'graph_title', epochs, './model/GBPJPY_12h/model.hdf5','./model/GBPJPY_12h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '13h'\n",
    "y_pred_13h, y_pred = learn(df, X_train, 'y_rate_13h', 'graph_title', epochs, './model/GBPJPY_13h/model.hdf5','./model/GBPJPY_13h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '14h'\n",
    "y_pred_14h, y_pred = learn(df, X_train, 'y_rate_13h', 'graph_title', epochs, './model/GBPJPY_14h/model.hdf5','./model/GBPJPY_14h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '15h'\n",
    "y_pred_15h, y_pred = learn(df, X_train, 'y_rate_15h', 'graph_title', epochs, './model/GBPJPY_15h/model.hdf5','./model/GBPJPY_15h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '16h'\n",
    "y_pred_16h, y_pred = learn(df, X_train, 'y_rate_16h', 'graph_title', epochs, './model/GBPJPY_16h/model.hdf5','./model/GBPJPY_16h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '17h'\n",
    "y_pred_17h, y_pred = learn(df, X_train, 'y_rate_17h', 'graph_title', epochs, './model/GBPJPY_17h/model.hdf5','./model/GBPJPY_17h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '18h'\n",
    "y_pred_18h, y_pred = learn(df, X_train, 'y_rate_18h', 'graph_title', epochs, './model/GBPJPY_18h/model.hdf5','./model/GBPJPY_18h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '19h'\n",
    "y_pred_19h, y_pred = learn(df, X_train, 'y_rate_19h', 'graph_title', epochs, './model/GBPJPY_19h/model.hdf5','./model/GBPJPY_19h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '20h'\n",
    "y_pred_20h, y_pred = learn(df, X_train, 'y_rate_20h', 'graph_title', epochs, './model/GBPJPY_20h/model.hdf5','./model/GBPJPY_20h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '21h'\n",
    "y_pred_21h, y_pred = learn(df, X_train, 'y_rate_21h', 'graph_title', epochs, './model/GBPJPY_21h/model.hdf5','./model/GBPJPY_21h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '22h'\n",
    "y_pred_22h, y_pred = learn(df, X_train, 'y_rate_22h', 'graph_title', epochs, './model/GBPJPY_22h/model.hdf5','./model/GBPJPY_22h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '23h'\n",
    "y_pred_23h, y_pred = learn(df, X_train, 'y_rate_23h', 'graph_title', epochs, './model/GBPJPY_23h/model.hdf5','./model/GBPJPY_23h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "graph_title = '24h'\n",
    "y_pred_24h, y_pred = learn(df, X_train, 'y_rate_24h', 'graph_title', epochs, './model/GBPJPY_24h/model.hdf5','./model/GBPJPY_24h/param.hdf5') # 学習関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_list = np.concatenate([y_pred_1h, y_pred_2h, y_pred_3h, y_pred_4h, y_pred_5h, y_pred_6h, y_pred_7h, y_pred_8h\n",
    "                           , y_pred_9h, y_pred_10h, y_pred_11h, y_pred_12h, y_pred_13h, y_pred_14h, y_pred_15h, y_pred_16h\n",
    "                           , y_pred_17h, y_pred_18h, y_pred_19h, y_pred_20h, y_pred_21h, y_pred_22h, y_pred_23h, y_pred_24h])# 5m, 1h, 4h, 8h, 1dの予測リスト\n",
    "\n",
    "def plot_pred(plot_list):\n",
    "    flg = plt.figure()\n",
    "    fig = plt.figure(figsize=(6, 4), dpi=72, linewidth=10)\n",
    "    ax = fig.add_subplot(111, xlabel='number', ylabel='price',title='title')  # グラフ作成\n",
    "    \n",
    "    ax.plot(plot_list, label='actual')  # 5m, 1h, 4h, 8h, 1dの予測リスト\n",
    "   # ax.plot(y_pred, label='predict')  # 予測\n",
    "    plt.legend()\n",
    "\n",
    "plot_pred(plot_list)\n",
    "print(plot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['y_rate_2h'].tolist() # Tolistを使う予定\n",
    "\n",
    "y = a - y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a))\n",
    "print(len(y_pred))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
